#!/usr/bin/env python3
"""
Live LlamaFarm Integration Demo

Shows Atmosphere routing to real LlamaFarm projects.
Requires: LlamaFarm running on localhost:14345
"""

import asyncio
import time

try:
    import httpx
except ImportError:
    print("‚ùå httpx not installed. Run: pip install httpx")
    exit(1)

LLAMAFARM_URL = "http://localhost:14345"


async def main():
    print("\nüåê ATMOSPHERE LIVE DEMO - Real LlamaFarm Integration\n")
    print("=" * 60)
    
    async with httpx.AsyncClient(timeout=60) as client:
        # 1. Check health
        print("\n1. Checking LlamaFarm health...")
        try:
            r = await client.get(f"{LLAMAFARM_URL}/health")
            health = r.json()
            print(f"   ‚úÖ LlamaFarm healthy: status={health.get('status')}")
            
            # Show component status
            components = health.get('components', [])
            healthy = sum(1 for c in components if c.get('status') == 'healthy')
            print(f"   üìä Components: {healthy}/{len(components)} healthy")
            
            # Show ollama models if available
            for c in components:
                if c.get('name') == 'ollama':
                    details = c.get('details', {})
                    model_count = details.get('model_count', 0)
                    print(f"   ü¶ô Ollama: {model_count} model(s) available")
                    
        except httpx.ConnectError:
            print(f"   ‚ùå LlamaFarm not reachable at {LLAMAFARM_URL}")
            print("   Start with: cd ~/clawd/projects/llamafarm-core/server && uv run python main.py")
            return
        except Exception as e:
            print(f"   ‚ùå Error: {e}")
            return
        
        # 2. List projects (discovery)
        print("\n2. Discovering projects...")
        projects_list = []
        try:
            # LlamaFarm projects API requires namespace in path
            r = await client.get(f"{LLAMAFARM_URL}/v1/projects/default")
            projects = r.json()
            projects_list = projects.get('projects', [])
            total = projects.get('total', len(projects_list))
            print(f"   üìÅ Found {total} projects in 'default' namespace")
            for p in projects_list[:5]:
                ns = p.get('namespace', 'default')
                name = p.get('name', 'unknown')
                print(f"      - {ns}/{name}")
            if total > 5:
                print(f"      ... and {total - 5} more")
        except Exception as e:
            print(f"   ‚ö†Ô∏è  Could not list projects: {e}")
        
        # 3. Check Universal Runtime
        print("\n3. Checking Universal Runtime...")
        try:
            r = await client.get("http://localhost:11540/health")
            ur_health = r.json()
            device = ur_health.get('device', {}).get('device', 'unknown')
            gpu = ur_health.get('device', {}).get('gpu_name', 'unknown')
            print(f"   ‚úÖ Universal Runtime healthy")
            print(f"   üñ•Ô∏è  Device: {device} ({gpu})")
            loaded = ur_health.get('loaded_models', [])
            if loaded:
                print(f"   üì¶ Loaded models: {', '.join(loaded)}")
            else:
                print(f"   üì¶ No models currently loaded (will load on demand)")
        except Exception as e:
            print(f"   ‚ö†Ô∏è  Universal Runtime: {e}")
        
        # 4. Route a chat completion (semantic routing)
        print("\n4. Testing chat completion routing...")
        
        # If we found projects, try using one for chat
        if projects_list:
            project = projects_list[0]
            ns = project.get('namespace', 'default')
            name = project.get('name')
            
            print(f"   üîÑ Trying project: {ns}/{name}")
            start = time.time()
            try:
                r = await client.post(
                    f"{LLAMAFARM_URL}/v1/projects/{ns}/{name}/chat/completions",
                    json={
                        "messages": [
                            {"role": "user", "content": "Say hello in exactly 5 words."}
                        ],
                        "max_tokens": 50,
                        "stream": False
                    }
                )
                elapsed = (time.time() - start) * 1000
                
                if r.status_code == 200:
                    result = r.json()
                    content = result.get('choices', [{}])[0].get('message', {}).get('content', 'No response')
                    content = content.strip()[:100]
                    print(f"   ‚úÖ Response in {elapsed:.0f}ms")
                    print(f"   üí¨ \"{content}\"")
                else:
                    print(f"   ‚ö†Ô∏è  Status {r.status_code}: {r.text[:100]}")
            except Exception as e:
                print(f"   ‚ö†Ô∏è  Error: {e}")
        else:
            print("   ‚ö†Ô∏è  No projects found to test chat completion")
        
        # Also try direct Ollama for comparison
        print("\n   ü¶ô Trying direct Ollama API...")
        start = time.time()
        try:
            r = await client.post(
                "http://localhost:11434/api/generate",
                json={
                    "model": "tinyllama:latest",
                    "prompt": "Say hello in exactly 5 words.",
                    "stream": False
                }
            )
            elapsed = (time.time() - start) * 1000
            
            if r.status_code == 200:
                result = r.json()
                content = result.get('response', 'No response').strip()[:100]
                print(f"   ‚úÖ Ollama response in {elapsed:.0f}ms")
                print(f"   üí¨ \"{content}\"")
            else:
                print(f"   ‚ö†Ô∏è  Ollama status {r.status_code}")
        except Exception as e:
            print(f"   ‚ö†Ô∏è  Ollama error: {e}")
        
        # 5. Demonstrate Atmosphere concepts
        print("\n" + "=" * 60)
        print("\n5. üåç ATMOSPHERE MESH CONCEPTS\n")
        
        print("   üì§ PUSH (Triggers):")
        print("      Camera detects motion")
        print("         ‚Üí fires 'motion_detected' event")
        print("         ‚Üí Atmosphere routes to security agent")
        print("         ‚Üí Agent receives event with image/metadata")
        
        print("\n   üì• PULL (Tools):")
        print("      Security agent needs more context")
        print("         ‚Üí calls camera.get_frame(camera_id='front')")
        print("         ‚Üí Atmosphere routes tool call to camera node")
        print("         ‚Üí Returns current frame to agent")
        
        print("\n   üîÑ BIDIRECTIONAL:")
        print("      Same mesh, same routing, both directions!")
        print("      Triggers PUSH to agents, agents PULL via tools")
        
        print("\n   üåê DISCOVERY:")
        project_count = len(projects_list) if projects_list else 0
        print(f"      LlamaFarm projects discovered: {project_count}")
        print("      Each project = potential routing target")
        print("      Semantic routing matches intent ‚Üí capability")
        
        print("\n" + "=" * 60)
        print("‚úÖ Demo complete!")
        print("=" * 60 + "\n")


if __name__ == "__main__":
    asyncio.run(main())
