# Atmosphere: Master Architecture

**The Internet of Intent â€” Route Intelligence, Not Packets**

---

## The Core Idea

Traditional networks route **packets** to **addresses**.

Atmosphere routes **work** to **capability**.

The question changes from *"Where is 192.168.1.50?"* to *"Who can analyze this image?"*

**This is the entire thesis.** Everything else serves this.

---

## The One Thing That Matters

### WHERE work gets done

A user asks: *"Summarize these 12 documents and compare them to last quarter's strategy."*

What happens:

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                                                                         â”‚
â”‚  Intent: "Summarize 12 docs, compare to strategy"                      â”‚
â”‚                                                                         â”‚
â”‚  Atmosphere decomposes this into WORK:                                 â”‚
â”‚                                                                         â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚ Work Unit 1: Embed doc 1     â†’ Node A (has embeddings, idle)    â”‚   â”‚
â”‚  â”‚ Work Unit 2: Embed doc 2     â†’ Node B (has embeddings, idle)    â”‚   â”‚
â”‚  â”‚ Work Unit 3: Embed doc 3     â†’ Node A (still has capacity)      â”‚   â”‚
â”‚  â”‚ Work Unit 4: Embed doc 4     â†’ Node C (just came online)        â”‚   â”‚
â”‚  â”‚ ...                                                              â”‚   â”‚
â”‚  â”‚ Work Unit 12: Embed doc 12   â†’ Node B                           â”‚   â”‚
â”‚  â”‚                                                                  â”‚   â”‚
â”‚  â”‚ Work Unit 13: RAG search     â†’ Node D (has vector DB)           â”‚   â”‚
â”‚  â”‚ Work Unit 14: Summarize      â†’ Node E (has 70B LLM, GPU)        â”‚   â”‚
â”‚  â”‚ Work Unit 15: Compare        â†’ Node E (already has context)     â”‚   â”‚
â”‚  â”‚ Work Unit 16: Format response â†’ Local (fastest)                 â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                                                                         â”‚
â”‚  12 embedding calls spread across 3 nodes in parallel: 200ms           â”‚
â”‚  RAG + summarize + compare on GPU node: 3s                             â”‚
â”‚  Total: ~3.5s instead of 30s sequential                                â”‚
â”‚                                                                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**This is what Atmosphere does.** It decides WHERE each piece of work runs based on:

1. **Capability** â€” Can this node do this work?
2. **Availability** â€” Is it online? Is it busy?
3. **Locality** â€” Is it close (low latency)?
4. **Cost** â€” Is there a cheaper option?
5. **Constraints** â€” Privacy? Latency requirements? Data residency?

---

## Core Principles

### 1. Bidirectional Capabilities

Every capability is both a **trigger** and a **tool**.

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                     BIDIRECTIONAL CAPABILITY                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                        â”‚
â”‚   PUSH (Trigger)                         PULL (Tool)                   â”‚
â”‚                                                                        â”‚
â”‚   Camera detects motion          â†â†’      Agent queries camera          â”‚
â”‚   Model finishes training        â†â†’      Agent invokes inference       â”‚
â”‚   Sensor hits threshold          â†â†’      Agent reads current value     â”‚
â”‚                                                                        â”‚
â”‚   Same capability. Same mesh. Both directions.                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Why this matters:**
- A camera isn't just a passive sensor you query
- A model isn't just an endpoint you call  
- Everything is a peer that can both **initiate** and **respond**

```yaml
capability:
  id: front-door-camera
  type: sensor/camera
  
  tools:      # What agents can PULL
    - get_frame: "Current camera snapshot"
    - get_history: "Motion events from last N minutes"
    
  triggers:   # What it can PUSH
    - motion_detected: "Intent routes to security agent"
    - person_detected: "High-priority, routes to notifications"
    - package_detected: "Routes to delivery tracking"
```

See [design/BIDIRECTIONAL_CAPABILITIES.md](design/BIDIRECTIONAL_CAPABILITIES.md) for the full specification.

### 2. Semantic Routing

Don't route to addresses. Route to meaning.

```python
# Traditional
requests.post("http://gpu-server-01.internal:8080/inference", data=image)

# Atmosphere
mesh.route("detect objects in this image", data=image)
# â†’ Automatically finds best node with vision capability
```

**How it works:**
- Every node advertises capabilities as embedding vectors
- Intents are embedded using the same model
- Cosine similarity finds the best match
- Gradient tables cache routes for speed

### 2. Edge-First

Work runs as close to the data as possible.

```
Sensor data â†’ Edge node (1ms away) â†’ Process locally
                â†“
        Only if edge can't handle it:
                â†“
            Cloud (100ms away)
```

**Why:**
- Latency: 1ms vs 100ms matters
- Bandwidth: Don't ship video to cloud
- Privacy: Data stays local when possible
- Resilience: Works when internet is down

### 3. Graceful Degradation

The mesh handles failure automatically.

| Event | Response |
|-------|----------|
| Node goes offline | Route to next-best node |
| Node is busy | Queue or route elsewhere |
| Rate limited | Back off, try alternatives |
| Network partition | Continue locally, sync later |

No single point of failure. No central coordinator that can die.

### 4. Super Scale

O(log N) everywhere.

| N (nodes) | Gossip rounds to propagate | Route lookup |
|-----------|---------------------------|--------------|
| 100 | 7 | O(1) gradient table |
| 10,000 | 14 | O(1) gradient table |
| 1,000,000 | 20 | O(1) gradient table |
| 1,000,000,000 | 30 | O(1) gradient table |

No central registry. No bottleneck. Nodes discover each other via gossip.

### 5. Useful Now

This isn't vaporware. Working today:

- âœ… Semantic routing with real embeddings
- âœ… 21-node mesh operational
- âœ… 100% routing accuracy in tests
- âœ… <15ms routing latency
- âœ… Zero-trust auth (offline verification)
- âœ… Visual designer showing topology

---

## The Protocol Stack

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                         WORK LAYER                                      â”‚
â”‚                                                                         â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚         PUSH (Triggers)       â”‚  â”‚         PULL (Tools)          â”‚  â”‚
â”‚  â”‚                               â”‚  â”‚                               â”‚  â”‚
â”‚  â”‚  Camera â†’ "motion detected"   â”‚  â”‚  Agent â†’ camera.get_frame()   â”‚  â”‚
â”‚  â”‚  Model â†’ "training complete"  â”‚  â”‚  Agent â†’ thermostat.set(72)   â”‚  â”‚
â”‚  â”‚  Sensor â†’ "threshold hit"     â”‚  â”‚  Agent â†’ model.classify(img)  â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚                                                                         â”‚
â”‚  Both directions use the same routing fabric below                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                    â”‚
                                    â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                         ROUTING LAYER                                   â”‚
â”‚                                                                         â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”         â”‚
â”‚  â”‚ Intent Embedder â”‚â†’ â”‚ Gradient Table  â”‚â†’ â”‚ Load Balancer   â”‚         â”‚
â”‚  â”‚ (384-dim vector)â”‚  â”‚ (capabilityâ†’hop)â”‚  â”‚ (availability)  â”‚         â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜         â”‚
â”‚                                                                         â”‚
â”‚  Semantic matching + routing decisions happen here                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                    â”‚
                                    â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                         MESH LAYER                                      â”‚
â”‚                                                                         â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”         â”‚
â”‚  â”‚ Gossip Protocol â”‚  â”‚ State Sync      â”‚  â”‚ Failure Detect  â”‚         â”‚
â”‚  â”‚ (propagation)   â”‚  â”‚ (CRDT merge)    â”‚  â”‚ (heartbeats)    â”‚         â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜         â”‚
â”‚                                                                         â”‚
â”‚  Nodes discover each other, share state, detect failures               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                    â”‚
                                    â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                         IDENTITY LAYER                                  â”‚
â”‚                                                                         â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”         â”‚
â”‚  â”‚ Rownd Local     â”‚  â”‚ Token Verify    â”‚  â”‚ Revocation      â”‚         â”‚
â”‚  â”‚ (Ed25519 keys)  â”‚  â”‚ (offline!)      â”‚  â”‚ (gossip-based)  â”‚         â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜         â”‚
â”‚                                                                         â”‚
â”‚  Zero-trust auth. Verify without calling home. Works in bunkers.       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                    â”‚
                                    â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                         TRANSPORT LAYER                                 â”‚
â”‚                                                                         â”‚
â”‚  Whatever moves bytes: TCP, UDP, QUIC, LoRa, BLE, WiFi, Carrier Pigeon â”‚
â”‚                                                                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## Work Distribution: The Core Algorithm

When work arrives, Atmosphere decides where it runs:

```python
def route_work(work_unit: WorkUnit) -> Node:
    """
    THE CORE ALGORITHM
    
    Input: A piece of work that needs to be done
    Output: The node that should do it
    """
    
    # 1. CAPABILITY MATCH
    # Find nodes that CAN do this work
    candidates = []
    for node in mesh.nodes:
        similarity = cosine_similarity(
            work_unit.embedding,
            node.capability_embedding
        )
        if similarity > 0.7:
            candidates.append((node, similarity))
    
    if not candidates:
        raise NoCapableNode("No node can handle this work")
    
    # 2. AVAILABILITY FILTER
    # Remove nodes that are offline, busy, or unhealthy
    available = []
    for node, score in candidates:
        if node.status != "online":
            continue
        if node.load > 0.9:  # >90% busy
            score *= 0.5  # Penalize but don't exclude
        if node.queue_depth > 10:
            score *= 0.7
        available.append((node, score))
    
    # 3. LOCALITY BONUS
    # Prefer nearby nodes (lower latency)
    for i, (node, score) in enumerate(available):
        latency_ms = get_latency(local_node, node)
        if latency_ms < 10:
            available[i] = (node, score * 1.3)  # Local bonus
        elif latency_ms < 50:
            available[i] = (node, score * 1.1)  # Same-site bonus
        elif latency_ms > 200:
            available[i] = (node, score * 0.8)  # Distance penalty
    
    # 4. CONSTRAINT CHECK
    # Apply any hard constraints from the work unit
    if work_unit.constraints.get("local_only"):
        available = [(n, s) for n, s in available if n.is_local]
    if work_unit.constraints.get("gpu_required"):
        available = [(n, s) for n, s in available if n.has_gpu]
    if work_unit.constraints.get("max_latency_ms"):
        max_lat = work_unit.constraints["max_latency_ms"]
        available = [(n, s) for n, s in available if get_latency(local_node, n) < max_lat]
    
    # 5. SELECT BEST
    available.sort(key=lambda x: x[1], reverse=True)
    return available[0][0]
```

---

## Parallel Work Distribution

The real power: spreading work across the mesh.

```python
async def execute_parallel(work_units: List[WorkUnit]) -> List[Result]:
    """
    Execute multiple work units in parallel across the mesh.
    This is how you summarize 12 docs in 200ms instead of 3s.
    """
    
    # Route each work unit to best node
    assignments = []
    for unit in work_units:
        node = route_work(unit)
        assignments.append((unit, node))
    
    # Execute all in parallel
    tasks = []
    for unit, node in assignments:
        task = asyncio.create_task(node.execute(unit))
        tasks.append(task)
    
    # Gather results (with timeout per unit)
    results = await asyncio.gather(*tasks, return_exceptions=True)
    
    # Handle failures gracefully
    final_results = []
    for i, result in enumerate(results):
        if isinstance(result, Exception):
            # Retry on different node
            unit = work_units[i]
            backup_node = route_work(unit, exclude=[assignments[i][1]])
            result = await backup_node.execute(unit)
        final_results.append(result)
    
    return final_results
```

**Example: 12-Document Summary**

```
Time 0ms:    Route 12 embed jobs â†’ 3 available nodes
Time 1ms:    All 12 jobs dispatched in parallel
Time 150ms:  Node A returns embeddings for docs 1, 3, 7, 10
Time 180ms:  Node B returns embeddings for docs 2, 6, 11, 12
Time 200ms:  Node C returns embeddings for docs 4, 5, 8, 9
Time 201ms:  Route RAG search â†’ Node D (has vector DB)
Time 500ms:  RAG results returned
Time 501ms:  Route summarization â†’ Node E (70B LLM)
Time 3000ms: Summary complete
Time 3001ms: Format and return to user

Total: 3 seconds
Sequential would be: 12 * 500ms + 300ms + 2500ms = 8.8 seconds
Speedup: 2.9x (and scales better with more nodes)
```

---

## The Gradient Table

How does a node know where to route without asking a central server?

**Gradient tables.** Each node maintains a local routing table that maps capability clusters to next-hop peers.

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    GRADIENT TABLE (on each node)                       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Capability Cluster  â”‚ Best Peer     â”‚ Hops â”‚ Score â”‚ Last Updated     â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ vision/detection    â”‚ jetson-01     â”‚ 2    â”‚ 0.91  â”‚ 2s ago           â”‚
â”‚ vision/detection    â”‚ cloud-gpu-01  â”‚ 5    â”‚ 0.94  â”‚ 5s ago           â”‚
â”‚ llm/70b             â”‚ dell-gpu      â”‚ 1    â”‚ 0.96  â”‚ 1s ago           â”‚
â”‚ llm/7b              â”‚ local         â”‚ 0    â”‚ 0.88  â”‚ now              â”‚
â”‚ embeddings          â”‚ local         â”‚ 0    â”‚ 0.92  â”‚ now              â”‚
â”‚ embeddings          â”‚ mac-studio    â”‚ 2    â”‚ 0.90  â”‚ 3s ago           â”‚
â”‚ rag/search          â”‚ home-server   â”‚ 1    â”‚ 0.85  â”‚ 2s ago           â”‚
â”‚ audio/transcribe    â”‚ cloud-whisper â”‚ 4    â”‚ 0.93  â”‚ 10s ago          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**How it's updated:**

1. **Capability Beacons**: Nodes broadcast their capabilities every 30s
2. **Gossip**: Beacons propagate via gossip (O(log N) rounds)
3. **Reinforcement**: Successful routes increase scores, failures decrease them
4. **Decay**: Stale entries (no beacon in 5 min) get pruned

---

## Handling Failures

The mesh self-heals.

### Node Goes Offline

```
T=0:     Node B stops responding
T=5s:    Heartbeat missed
T=10s:   Second heartbeat missed, mark "suspect"
T=30s:   Third miss, mark "offline"
T=30.1s: Gradient table updated, routes through B removed
T=30.2s: Next work unit that would have gone to B â†’ routes to C instead
```

### Node Overwhelmed

```
T=0:     Node A reports 95% CPU, queue depth 15
T=0.1s:  State propagates via gossip
T=1s:    All nodes see A is busy
T=1.1s:  Work that would score A highest now penalized
T=1.2s:  Work routes to B instead (second-best capability match)
T=60s:   A's load drops to 40%
T=61s:   A becomes preferred again
```

### Network Partition

```
Site 1                          Site 2
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Node A       â”‚    PARTITION   â”‚ Node C       â”‚
â”‚ Node B       â”‚ â•â•â•â•â•â•â•â•â•â•â•â•â•â• â”‚ Node D       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

T=0:     Partition occurs
T=30s:   Sites detect they can't reach each other
T=31s:   Each site continues operating independently
         - Site 1: A and B still route to each other
         - Site 2: C and D still route to each other
T=???:   Partition heals
T=+1s:   Gossip resumes, gradient tables merge
T=+5s:   Full mesh restored, routes optimized
```

---

## Identity & Trust

Zero-trust authentication that works offline.

### The Problem

Traditional auth needs a server:
```
Client â†’ "Is this token valid?" â†’ Auth Server â†’ "Yes/No"
```

This fails when:
- Internet is down
- Auth server is unreachable
- You're in a bunker

### The Atmosphere Solution

Tokens are self-verifying:

```python
# Token structure (simplified)
token = {
    "node_id": "abc123",
    "capabilities": ["vision", "llm"],
    "issued_at": 1706900000,
    "expires_at": 1706986400,  # 24h later
    "signature": "ed25519_sig_of_above_fields"
}

# Verification (NO NETWORK CALL)
def verify_token(token, mesh_public_key):
    # Check signature
    if not ed25519_verify(mesh_public_key, token.signature):
        return False, "Invalid signature"
    
    # Check expiration
    if time.time() > token.expires_at:
        return False, "Expired"
    
    # Check revocation (local cache, updated via gossip)
    if token.node_id in revocation_cache:
        return False, "Revoked"
    
    return True, "Valid"
```

**Key insight:** The mesh public key is the only thing you need. It's distributed once, then every node can verify every token forever (until expiry) without calling anyone.

---

## Integration Points

Atmosphere doesn't replace your AI stack. It orchestrates it.

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                         ATMOSPHERE MESH                                 â”‚
â”‚                                                                         â”‚
â”‚  Routes work to capabilities, doesn't care what provides them          â”‚
â”‚                                                                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                 â”‚
         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
         â”‚                       â”‚                       â”‚
         â–¼                       â–¼                       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   LlamaFarm     â”‚    â”‚     Ollama      â”‚    â”‚     vLLM        â”‚
â”‚                 â”‚    â”‚                 â”‚    â”‚                 â”‚
â”‚ - Projects      â”‚    â”‚ - Models        â”‚    â”‚ - High-perf     â”‚
â”‚ - RAG           â”‚    â”‚ - Simple API    â”‚    â”‚ - Batching      â”‚
â”‚ - Agents        â”‚    â”‚ - Local         â”‚    â”‚ - GPU optimized â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚                       â”‚                       â”‚
         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                 â”‚
                                 â–¼
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚    Actual Hardware      â”‚
                    â”‚                         â”‚
                    â”‚  CPU, GPU, TPU, NPU     â”‚
                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

Atmosphere provides:
- **Discovery**: "LlamaFarm is running on this node with these capabilities"
- **Routing**: "This work needs RAG, LlamaFarm has it, route there"
- **Load balancing**: "Ollama on Node A is busy, try Node B"
- **Failover**: "vLLM crashed, fall back to Ollama"

---

## What Changes the World

Traditional AI:
```
User â†’ Cloud API â†’ Response
       (100ms+, requires internet, data leaves your control)
```

Atmosphere AI:
```
User â†’ Mesh â†’ Wherever is best â†’ Response
       (1ms-100ms, works offline, data stays where you want)
```

**The shift:**
- From "send data to the AI" to "send AI to the data"
- From "one big model in the cloud" to "many specialized models everywhere"
- From "pray the API is up" to "mesh self-heals"
- From "trust the cloud provider" to "trust the math"

---

## Implementation Status

| Component | Status | Notes |
|-----------|--------|-------|
| Semantic routing | âœ… Working | 100% accuracy, 14.5ms latency |
| Gradient tables | âœ… Working | Local lookup, gossip updates |
| Gossip protocol | âœ… Working | O(log N) propagation |
| Zero-trust auth | âœ… Working | Offline verification |
| Parallel dispatch | ğŸŸ¡ Basic | Needs production hardening |
| Failure recovery | ğŸŸ¡ Basic | Needs more testing |
| LlamaFarm adapter | âœ… Designed | Implementation needed |
| Ollama adapter | âœ… Designed | Implementation needed |
| Matter bridge | âœ… Designed | Implementation needed |

---

## Next Steps

1. **Harden parallel dispatch** â€” Production-ready work distribution
2. **Build adapters** â€” LlamaFarm, Ollama, Matter integrations
3. **Multi-node demo** â€” Mac + Dell + Jetson working together
4. **Load testing** â€” 1000+ concurrent work units
5. **Documentation** â€” Full API reference, tutorials

---

## The Vision

A world where:
- Every device with compute joins the mesh
- Work flows to the best place automatically
- Internet optional, not required
- No single company controls the infrastructure
- AI is as available as electricity

**This is the Internet of Intent.**

---

*Document Version: 1.0*  
*Date: 2026-02-02*  
*Core Focus: Semantic routing, work distribution, edge-first, resilient mesh*
