# Atmosphere

> **The Internet of Intent** â€” Route intelligence to capability, not packets to addresses.

[![License: Apache 2.0](https://img.shields.io/badge/License-Apache%202.0-blue.svg)](LICENSE)
[![Python 3.10+](https://img.shields.io/badge/python-3.10+-blue.svg)](https://www.python.org/downloads/)

**Atmosphere** is a semantic mesh protocol that routes AI requests to the right capability on the right node. Instead of hardcoding which model handles which request, Atmosphere discovers capabilities across a distributed mesh and routes intelligently based on intent.

## ğŸ“„ White Paper

For the full technical deep-dive, see the **[Atmosphere Protocol White Paper](https://drive.google.com/file/d/1-LmkSI4cMZcQiCG6uUgJSerJi2FwUNli/view?usp=sharing)**.

---

## ğŸ¯ What Problem Does This Solve?

**Traditional AI APIs:**
```
Client â†’ knows exact endpoint â†’ calls specific model
```

**Atmosphere:**
```
Client â†’ expresses intent â†’ mesh routes to best capability
```

### Example

```bash
# Traditional: You must know exactly which model to call
curl https://api.openai.com/v1/chat/completions \
  -d '{"model": "gpt-4", "messages": [...]}'

# Atmosphere: Express intent, mesh finds the right capability
curl http://localhost:8000/v1/chat/completions \
  -d '{"model": "auto", "messages": [{"role": "user", "content": "What do llamas eat?"}]}'

# Atmosphere routes to the "llama-expert" project with RAG database
# because it semantically matches the query
```

---

## âœ¨ Key Features

- **ğŸ” Semantic Routing** â€” Routes based on intent, not hardcoded paths
- **ğŸŒ Mesh Networking** â€” Discover capabilities across distributed nodes
- **ğŸ”Œ OpenAI Compatible** â€” Drop-in replacement for OpenAI API
- **âš¡ Fast Routing** â€” Pre-computed embeddings, sub-millisecond decisions
- **ğŸ“¦ Model Deployment** â€” Automatically distribute models across the mesh
- **ğŸ”„ Gossip Protocol** â€” Sync routing tables without central authority
- **ğŸ‘ï¸ Multi-Modal** â€” Route text, images, audio, and tool calls
- **ğŸ¤– Agent Framework** â€” Discover and invoke agents across the mesh
- **ğŸ”§ Tool Execution** â€” Execute tools on remote nodes (cameras, IoT, APIs)

---

## ğŸ¦Œ The Vision: Capability Mesh

Atmosphere isn't just for text â€” it routes **any intent** to **any capability**:

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                      CAPABILITY MESH                                 â”‚
â”‚                                                                      â”‚
â”‚   "What is this?"     "Research llamas"    "Take a photo"          â”‚
â”‚         â”‚                    â”‚                   â”‚                  â”‚
â”‚         â–¼                    â–¼                   â–¼                  â”‚
â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”             â”‚
â”‚   â”‚  Vision  â”‚        â”‚  Agent   â”‚        â”‚   Tool   â”‚             â”‚
â”‚   â”‚ Classify â”‚        â”‚ Research â”‚        â”‚  Camera  â”‚             â”‚
â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜             â”‚
â”‚         â”‚                    â”‚                   â”‚                  â”‚
â”‚         â–¼                    â–¼                   â–¼                  â”‚
â”‚      rob-mac              rob-mac           edge-gateway            â”‚
â”‚   (has YOLO model)    (has research agent)  (has camera)           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Example: The Deer Scenario

A tiny edge sensor sees movement but can't identify the animal:

```
Edge Sensor â†’ "I see an animal" (low confidence)
      â†“
Mesh Routes â†’ rob-mac (has wildlife classifier)
      â†“
Classification â†’ "White-tailed deer" (94% confidence)
      â†“
Learning Loop â†’ Train edge model â†’ Deploy back
      â†“
Next time â†’ Sensor handles locally
```

See [design/CAPABILITY_MESH.md](design/CAPABILITY_MESH.md) for the full architecture.

---

## ğŸš€ Quick Start

### Prerequisites

- Python 3.10+
- [LlamaFarm](https://github.com/llama-farm/llamafarm) (for local model execution)

### Installation

```bash
# Clone the repository
git clone https://github.com/llama-farm/atmosphere.git
cd atmosphere

# Create virtual environment
python -m venv .venv
source .venv/bin/activate

# Install dependencies
pip install -e .

# Start Atmosphere
uvicorn atmosphere.api.server:create_app --factory --port 8000
```

### Quick Test

```bash
# List available models (discovered from LlamaFarm)
curl http://localhost:8000/v1/models

# Chat with semantic routing
curl -X POST http://localhost:8000/v1/chat/completions \
  -H "Content-Type: application/json" \
  -d '{
    "model": "auto",
    "messages": [{"role": "user", "content": "Hello!"}]
  }'
```

---

## ğŸ—ï¸ Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                         ATMOSPHERE                               â”‚
â”‚                                                                  â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”       â”‚
â”‚  â”‚   OpenAI     â”‚    â”‚   Semantic   â”‚    â”‚    Mesh      â”‚       â”‚
â”‚  â”‚   API Layer  â”‚â”€â”€â”€â–¶â”‚    Router    â”‚â”€â”€â”€â–¶â”‚   Network    â”‚       â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜       â”‚
â”‚         â”‚                   â”‚                   â”‚                â”‚
â”‚         â–¼                   â–¼                   â–¼                â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”       â”‚
â”‚  â”‚                    DISCOVERY                          â”‚       â”‚
â”‚  â”‚  â€¢ API-based project discovery                        â”‚       â”‚
â”‚  â”‚  â€¢ Pre-computed embeddings for fast matching          â”‚       â”‚
â”‚  â”‚  â€¢ Domain/topic/capability indexing                   â”‚       â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜       â”‚
â”‚                              â”‚                                   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”‚â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                               â”‚
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â–¼                      â–¼                      â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  LlamaFarm   â”‚      â”‚   Ollama     â”‚      â”‚   OpenAI     â”‚
â”‚  (Universal  â”‚      â”‚              â”‚      â”‚   (Cloud)    â”‚
â”‚   Runtime)   â”‚      â”‚              â”‚      â”‚              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ”§ How It Works

### 1. Discovery

Atmosphere discovers AI capabilities by querying provider APIs:

```python
# Discovers projects from LlamaFarm API
discovery = APIDiscovery("http://localhost:14345")
projects = await discovery.discover()

# Returns structured metadata:
# {
#   "namespace": "default",
#   "name": "llama-expert-14",
#   "domain": "camelids",
#   "capabilities": ["chat", "rag"],
#   "topics": ["llamas", "alpacas", "fiber"]
# }
```

### 2. Routing

The semantic router uses pre-computed embeddings for fast matching:

```python
# Route by explicit path
result = router.route("default/llama-expert-14")

# Route by content (semantic)
result = router.route_by_content([
    {"role": "user", "content": "How do I care for my llama?"}
])
# â†’ Routes to llama-expert project (domain: camelids)
```

### 3. Execution

Requests are proxied to the appropriate backend:

```python
# Atmosphere â†’ LlamaFarm â†’ Universal Runtime
POST /v1/projects/default/llama-expert-14/chat/completions
```

---

## ğŸ”Œ Extending to Other Providers

Atmosphere is designed to be provider-agnostic. Add new providers by implementing the adapter interface:

### Creating a Custom Adapter

```python
# atmosphere/adapters/my_provider.py

from atmosphere.adapters.base import BaseAdapter

class MyProviderAdapter(BaseAdapter):
    """Adapter for MyProvider API."""
    
    def __init__(self, base_url: str, api_key: str = None):
        self.base_url = base_url
        self.api_key = api_key
    
    async def discover(self) -> list[Project]:
        """Discover available models/capabilities."""
        # Query your provider's API
        response = await self.client.get(f"{self.base_url}/models")
        
        projects = []
        for model in response.json()["models"]:
            projects.append(Project(
                namespace="myprovider",
                name=model["id"],
                domain=self._detect_domain(model),
                capabilities=["chat"],
            ))
        return projects
    
    async def chat(self, project: Project, messages: list) -> dict:
        """Execute a chat completion."""
        response = await self.client.post(
            f"{self.base_url}/chat",
            json={"model": project.name, "messages": messages}
        )
        return response.json()
```

### Registering the Adapter

```python
# atmosphere/config.py

ADAPTERS = {
    "llamafarm": LlamaFarmAdapter,
    "ollama": OllamaAdapter,
    "openai": OpenAIAdapter,
    "myprovider": MyProviderAdapter,  # Add your adapter
}
```

### Built-in Adapters

| Adapter | Description | Status |
|---------|-------------|--------|
| `LlamaFarmAdapter` | LlamaFarm Universal Runtime | âœ… Complete |
| `OllamaAdapter` | Ollama local models | âœ… Complete |
| `OpenAIAdapter` | OpenAI API (cloud) | ğŸ”„ Planned |
| `AnthropicAdapter` | Anthropic Claude | ğŸ”„ Planned |
| `vLLMAdapter` | vLLM inference server | ğŸ”„ Planned |

---

## ğŸŒ Mesh Networking

Atmosphere nodes discover each other and share routing information via gossip protocol.

### Starting a Mesh

```bash
# Node 1 (Rob's Mac)
atmosphere start --port 11451 --gossip-port 11450

# Node 2 (Matt's Dell) - joins the mesh
atmosphere start --port 11451 --gossip-port 11450 \
  --seed-peer "rob-mac.local:11450"
```

### Gossip Messages

```python
# When a new project is discovered
ROUTE_UPDATE = {
    "type": "route_update",
    "action": "add",
    "project": "default/llama-expert-14",
    "domain": "camelids",
    "capabilities": ["chat", "rag"],
    "nodes": ["rob-mac"]
}

# When a model is deployed
MODEL_DEPLOYED = {
    "type": "model_deployed",
    "model": "network-anomaly-v3",
    "node": "matt-dell",
    "version": "1.0.0"
}
```

---

## ğŸ“¦ Model Deployment

Automatically distribute trained models across the mesh:

```bash
# List local models
atmosphere model list

# Push model to specific node
atmosphere model push network-detector matt-dell

# Deploy to all capable nodes
atmosphere model deploy network-detector --all
```

### Model Manifest

```yaml
name: network-anomaly-detector
version: 1.0.0
type: anomaly_detector
format: sklearn
size_bytes: 12345678

capabilities:
  - anomaly_detection
  - network_monitoring

node_requirements:
  min_memory_mb: 512
  gpu_required: false
```

---

## ğŸ¯ Typed Intents (Coming Soon)

Beyond OpenAI-compatible chat, Atmosphere supports typed intents for any capability:

```bash
# Vision classification
curl -X POST http://localhost:8000/v1/intent \
  -d '{
    "type": "vision/classify",
    "domain": "wildlife",
    "data": {"image": "<base64>"},
    "preferences": {"latency": "low"}
  }'

# Agent invocation
curl -X POST http://localhost:8000/v1/agent/invoke \
  -d '{
    "query": "Research the latest on llama breeding"
  }'

# Tool execution
curl -X POST http://localhost:8000/v1/tool/execute \
  -d '{
    "tool": "camera-front@edge-gateway",
    "action": "capture"
  }'
```

### Supported Capability Types

| Category | Types | Description |
|----------|-------|-------------|
| **LLM** | chat, reasoning, code, summarize | Text generation |
| **Vision** | classify, detect, ocr, segment | Image processing |
| **Audio** | transcribe, generate, identify | Audio processing |
| **Agent** | research, workflow, monitor | Autonomous tasks |
| **Tool** | camera, iot, api, file | Device/API control |
| **ML** | anomaly, classify, forecast | ML inference |

---

## ğŸ›£ï¸ Roadmap

- [x] **Phase 1**: Single-node routing with LlamaFarm
- [x] **Phase 2**: OpenAI-compatible API layer
- [x] **Phase 3**: API-based discovery
- [ ] **Phase 4**: Multi-node mesh networking
- [ ] **Phase 5**: Model deployment & distribution
- [ ] **Phase 6**: Edge learning loop (train â†’ deploy â†’ learn)
- [ ] **Phase 7**: Typed intents (vision, audio, agents, tools)
- [ ] **Phase 8**: Distributed embeddings (SimHash for edge devices)

---

## ğŸ“ Project Structure

```
atmosphere/
â”œâ”€â”€ api/                    # FastAPI server
â”‚   â”œâ”€â”€ server.py          # Main application
â”‚   â””â”€â”€ routes.py          # API routes
â”œâ”€â”€ router/                 # Semantic routing
â”‚   â”œâ”€â”€ fast_router.py     # Embedding-based router
â”‚   â”œâ”€â”€ openai_compat.py   # OpenAI API compatibility
â”‚   â””â”€â”€ project_router.py  # Project routing logic
â”œâ”€â”€ discovery/              # Capability discovery
â”‚   â”œâ”€â”€ api_discovery.py   # API-based discovery
â”‚   â””â”€â”€ llamafarm.py       # LlamaFarm adapter
â”œâ”€â”€ deployment/             # Model deployment
â”‚   â””â”€â”€ registry.py        # Model registry
â”œâ”€â”€ mesh/                   # Mesh networking
â”‚   â”œâ”€â”€ discovery.py       # mDNS/gossip discovery
â”‚   â”œâ”€â”€ gossip.py          # Gossip protocol
â”‚   â””â”€â”€ network.py         # STUN/NAT traversal
â”œâ”€â”€ adapters/               # Provider adapters
â”‚   â”œâ”€â”€ llamafarm.py       # LlamaFarm adapter
â”‚   â””â”€â”€ ollama.py          # Ollama adapter
â””â”€â”€ design/                 # Design documents
    â””â”€â”€ MODEL_DEPLOYMENT.md
```

---

## ğŸ¤ Contributing

Contributions are welcome! Please read our [Contributing Guide](CONTRIBUTING.md) for details.

### Development Setup

```bash
# Clone and setup
git clone https://github.com/llama-farm/atmosphere.git
cd atmosphere
python -m venv .venv
source .venv/bin/activate
pip install -e ".[dev]"

# Run tests
pytest tests/ -v

# Run linting
ruff check .
```

---

## ğŸ“œ License

Apache 2.0 - See [LICENSE](LICENSE) for details.

---

## ğŸ”— Related Projects

- [LlamaFarm](https://github.com/llama-farm/llamafarm) - Edge AI runtime
- [Rownd-Local](https://github.com/llama-farm/rownd-local) - Decentralized identity for mesh auth

---

<p align="center">
  <b>Route intelligence, not packets.</b>
</p>
